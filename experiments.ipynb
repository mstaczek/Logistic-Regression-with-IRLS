{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 1 - Breast Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "X, Y = load_breast_cancer(return_X_y=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from collinearity import SelectNonCollinear\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def remove_missing_rows(X, Y):\n",
    "    mask = np.isnan(X).sum(axis=1) == 0\n",
    "    return X[mask], Y[mask]\n",
    "\n",
    "def encode_categorical(X):\n",
    "    mask = np.array([isinstance(x, str) for x in X[0]])\n",
    "    if mask.sum() > 0:    \n",
    "        X = X[:, mask]\n",
    "        enc = OneHotEncoder(handle_unknown='ignore')\n",
    "        enc.fit(X)\n",
    "        X = enc.transform(X).toarray()\n",
    "    return X\n",
    "\n",
    "def remove_colinear(X, correlation_threshold=0.9):\n",
    "    # Source: https://github.com/gianlucamalato/collinearity\n",
    "    # 1. Take the couple of features that have the lowest absolute \n",
    "    #    value of the linear correlation coefficient.\n",
    "    # 2. If it's lower than the threshold, consider these features\n",
    "    # 3. Keep adding features as long as the correlation matrix doesn't\n",
    "    #    show off-diagonal elements whose absolute value is greater than the threshold.\n",
    "    selector = SelectNonCollinear(correlation_threshold=correlation_threshold)\n",
    "    selector.fit(X, y=None)\n",
    "    X = selector.transform(X)\n",
    "    columns_selection = selector.get_support()\n",
    "    return X, columns_selection   \n",
    "\n",
    "def scale_features(X):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    return X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before preparation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the raw data, there are 569 observations and 30 features.\n"
     ]
    }
   ],
   "source": [
    "print(f\"In the raw data, there are {X.shape[0]} observations and {X.shape[1]} features.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping rows with missing values, encoding categorical variables, dropping features with correlation > 0.9, and scaling the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = remove_missing_rows(X, Y)\n",
    "X = encode_categorical(X)\n",
    "X, columns_selection = remove_colinear(X, correlation_threshold=0.9)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After preparation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the prepared data, there are 569 observations and 21 features (removed 9 features).\n"
     ]
    }
   ],
   "source": [
    "print(f\"In the prepared data, there are {X.shape[0]} observations and {X.shape[1]} features (removed {len(columns_selection) - np.array(columns_selection).sum()} features).\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from LogisticRegressionIRLS import LR\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from functools import partial\n",
    "\n",
    "models = {'LDA': LinearDiscriminantAnalysis,\n",
    "        'QDA': QuadraticDiscriminantAnalysis,\n",
    "        'Logistic Regression': LogisticRegression,\n",
    "        'Logistic Regression IRLS': LR,\n",
    "        'KNN': KNeighborsClassifier}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision, recall, accuracy, f1\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "metrics = {'precision': precision_score,\n",
    "            'recall': recall_score,\n",
    "            'accuracy': accuracy_score,\n",
    "            'f1': f1_score}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m     Y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m      4\u001b[0m     \u001b[39mreturn\u001b[39;00m {metric: metrics[metric](Y_test, Y_pred) \u001b[39mfor\u001b[39;00m metric \u001b[39min\u001b[39;00m metrics}\n\u001b[1;32m----> 6\u001b[0m results \u001b[39m=\u001b[39m {model: train_model(models[model](), X_train, Y_train, X_test, Y_test, metrics) \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m models}\n",
      "Cell \u001b[1;32mIn[66], line 6\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      3\u001b[0m     Y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m      4\u001b[0m     \u001b[39mreturn\u001b[39;00m {metric: metrics[metric](Y_test, Y_pred) \u001b[39mfor\u001b[39;00m metric \u001b[39min\u001b[39;00m metrics}\n\u001b[1;32m----> 6\u001b[0m results \u001b[39m=\u001b[39m {model: train_model(models[model](), X_train, Y_train, X_test, Y_test, metrics) \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m models}\n",
      "Cell \u001b[1;32mIn[66], line 2\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, X_train, Y_train, X_test, Y_test, metrics)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_model\u001b[39m(model, X_train, Y_train, X_test, Y_test, metrics):\n\u001b[1;32m----> 2\u001b[0m     model\u001b[39m.\u001b[39;49mfit(X_train, Y_train)\n\u001b[0;32m      3\u001b[0m     Y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m      4\u001b[0m     \u001b[39mreturn\u001b[39;00m {metric: metrics[metric](Y_test, Y_pred) \u001b[39mfor\u001b[39;00m metric \u001b[39min\u001b[39;00m metrics}\n",
      "File \u001b[1;32mt:\\studies\\py_projects\\aml_project\\Logistic-Regression-with-IRLS\\LogisticRegressionIRLS.py:23\u001b[0m, in \u001b[0;36mLR.fit\u001b[1;34m(self, X, Y, iter_max, interactions, l2)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, Y, iter_max \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m, interactions \u001b[39m=\u001b[39m [], l2\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m): \n\u001b[0;32m     14\u001b[0m     \n\u001b[0;32m     15\u001b[0m     \u001b[39m# X- DataFrame of predictors\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[39m# interactions- a matrix with two columns, in which each row specifies a pair of variables between which we want to consider interactions\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     \u001b[39m# l2- ridge regularization strength\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m     X\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mc_[np\u001b[39m.\u001b[39mones(X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]) , X\u001b[39m.\u001b[39;49mvalues]\n\u001b[0;32m     24\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minteractions \u001b[39m=\u001b[39m interactions\n\u001b[0;32m     25\u001b[0m     \u001b[39mfor\u001b[39;00m interaction \u001b[39min\u001b[39;00m interactions:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "def train_model(model, X_train, Y_train, X_test, Y_test, metrics):\n",
    "    model.fit(X_train, Y_train)\n",
    "    Y_pred = model.predict(X_test)\n",
    "    return {metric: metrics[metric](Y_test, Y_pred) for metric in metrics}\n",
    "\n",
    "results = {model: train_model(models[model](), X_train, Y_train, X_test, Y_test, metrics) for model in models}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
